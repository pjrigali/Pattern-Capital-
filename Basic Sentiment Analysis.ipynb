{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Sentiment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pattern\n",
    "from pattern.en import lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load General Purpose Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = \"$?:!.,;/\\\\&*)--(...-``''\"\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "dict_word_score = {}\n",
    "for line in urlopen(\"http://ptrckprry.com/course/ssd/data/positive-words.txt\"):\n",
    "    if not (line.startswith(';'.encode()) or line.startswith(' '.encode())):\n",
    "        dict_word_score[line.rstrip('\\n'.encode())] = 1\n",
    "for line in urlopen(\"http://ptrckprry.com/course/ssd/data/negative-words.txt\"):\n",
    "    if not (line.startswith(';'.encode()) or line.startswith(' '.encode())):\n",
    "        dict_word_score[line.rstrip('\\n'.encode())] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Sentiment Score for str fed to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(corpus):\n",
    "    return np.sum([dict_word_score[x.encode()] for x in corpus if x.encode() in dict_word_score]) * 1. / len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input whatever text you are looking to score in raw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"Thank you, President Mester and Treye Johnson, and thanks to everyone for joining us. My job today is to listen, so I will keep my remarks short. But I do want to say that these conversations are incredibly valuable. They give context to reams of data and definition to a huge and complex economic picture. They also help solve problems on a practical level. Feedback from our Investing in America's Workforce initiative found a pronounced need for workforce and economic development programs to more closely align, for instance. And employers' input has influenced work across the Fed System, including the Cleveland Fed, as they look at how skills on the lower end of the pay scale can transfer to higher-earning jobs. So from me, and on behalf of my colleagues: Thank you for your time today and for your ongoing insight.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word.lower() for word in word_tokenize(raw.replace(\".\",\" \")) if not word in punctuations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.add(\"'s\"), stop_words.add(\"'ve\"), stop_words.add(\"'m\"), stop_words.add(\"'re\"), stop_words.add(\"'ll\")\n",
    "filtered_tokens = [word for word in tokens if not word in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatize Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_tokens = [lemma(words) for words in filtered_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = sentiment_score(nltk.Text(lemm_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06578947368421052\n"
     ]
    }
   ],
   "source": [
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
